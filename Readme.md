# Times Higher Education Data Engineering take home test

At Time Higher Education our aim is give the best insights we can into higher education for both students and academics. In this test, we'd like to give you a taste of some of the problems we deal and how you can contribute that vision.

In this repository we've given you some autogenerated dummy data about some higher education institutions that could have submitted to us. What we would like you to do is take this data, put it through an ETL process, put it into a data store, and tell us an interesting insight about the processed data; there are some suggestions below to inspire you but feel free to use your imagination.

The aim is to have something to show us how you approach the problem technically, and have something concrete to talk about in the later technical interview. There are no hard and fast rules but there some guidelines as to what we're expecting:

 - Ideally spend between 1 to 2 hours on the problem; you can spend a little more if you want but we don't want this to be a chore or an exercise of how much you can achieve in a time limit. We'd rather have one solid interesting technical point to talk about than something very wide but shallow.
 - Based on the time constraints, it's better to think small and complete and have ideas of what/how you'd do something bigger. Part of the technical interview will be looking at the limitations of what you did and talking through what you'd do if had more time.
 - We would like to see some code/scripts of what you've done; we're pretty flexible in terms of language/tools as long as it's nothing too obscure.
 - Likewise we're not expecting something production ready or capable of operating at extreme scale, but it should reflect how you approach the problem normally rather than something you'd throw away afterwards.

# Files

There are two groups of files, `institutions.json` and a list of submitted data by year; an institution is a university or other higher education body, and a submission is some data they told us about themselves for a particular year. There is a foreign key from submission to institution and broadly speaking the fields are fairly self explanatory. N.B. this data is auto generated so there may not be obvious trends and numbers may not add up to produce totals you'd expect.

The `yml` files were generate from `generate_data.py` which doesn't have to run again.

# Suggestions
Here are a list of some examples of questions you could ask from the data; feel free to use one of these but also feel free to try something else if you feel inspired.

 - Which institution has the lowest student to staff ratio?
 - For each subject, rank the institutions by their average rating
 - Who published the most accademic papers by each year?

The data store itself can be something very simple as long as it can be queried in some way.